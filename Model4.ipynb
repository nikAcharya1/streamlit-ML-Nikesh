{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513dc7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This program trains a binary classification model on image data (human face images with and without eyeglasses), \n",
    "saves the trained model, and classifies new/test images using the model. Also called binary image classification model. \n",
    "It constructs a custom model on top of the pre-trained base model employing transfer learning.\n",
    "The trained model predicts/classifies the test/new images as: 0 - No Eye glasses & 1 - Eye glasses present.\n",
    "\n",
    "This program will be hosted online via Streamlit community cloud. \n",
    "Streamlit web app will be created that allows users to upload an image, classify it using pre-trained models, and\n",
    "display the result.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247157d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define training and validation directories\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'test'\n",
    "\n",
    "# Image dimensions\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Setting up training parameters\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "# Create base model with pre-trained weights on ImageNet\n",
    "base_model = MobileNetV2(input_shape=(img_width, img_height, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build your own model on top of the base model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Normalization for validation/testing\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,  # You can adjust the number of epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('Model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b6f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Classification report\n",
    "\n",
    "import os\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define training and validation directories\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'test'\n",
    "\n",
    "# Image dimensions\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Normalization for validation/testing\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the saved model\n",
    "from keras.models import load_model\n",
    "model = load_model('Model4.h5')\n",
    "\n",
    "# Generate predictions for the validation dataset\n",
    "validation_generator.reset()  # Reset generator to start from beginning\n",
    "y_pred = model.predict_generator(validation_generator, steps=len(validation_generator), verbose=1)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Get true labels\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_true, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting loss and accuracy over epochs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "# Plotting loss & validation loss\n",
    "plt.subplot(1,2,1)\n",
    "sns.lineplot(x=history.epoch, y=history.history['loss'], color='red', label='Train Loss')\n",
    "sns.lineplot(x=history.epoch, y=history.history['val_loss'], color='orange', label='Val Loss')\n",
    "plt.title('Loss on train vs test')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Plotting accuracy and validation accuracy\n",
    "plt.subplot(1,2,2)\n",
    "sns.lineplot(x=history.epoch, y=history.history['accuracy'], color='blue', label='Train Accuracy')\n",
    "sns.lineplot(x=history.epoch, y=history.history['val_accuracy'], color='green', label='Val Accuracy')\n",
    "plt.title('Accuracy on train vs test')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e83fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the trained model, using it to classify for images in batch\n",
    "# and exporting classification results to an Excel file.\n",
    "\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "model = load_model('Model4.h5')\n",
    "\n",
    "# Making predictions on test/new images using the trained model from the above.\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Setting the directory for testing images\n",
    "folder_dir = \"/Users/tabal/Downloads/new_faces\"\n",
    "\n",
    "# Create an empty list to store prediction results\n",
    "prediction_results = []\n",
    "\n",
    "# Looping through each image in the directory\n",
    "for image in glob.iglob(f'{folder_dir}/*'):\n",
    "    \n",
    "    # Loading and preprocessing the image\n",
    "    load_image = load_img(image, target_size=(224, 224))\n",
    "    img = img_to_array(load_image)\n",
    "    img = preprocess_input(img.reshape(1,224,224,3))\n",
    "    \n",
    "    # Making predictions using the loaded model\n",
    "    label = model.predict(img)\n",
    "    \n",
    "    # Append the prediction results to the list\n",
    "    prediction_results.append({\n",
    "        'Image Name': os.path.basename(image),\n",
    "        'Prediction': round(label[0][0])})\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df = pd.DataFrame(prediction_results)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('classification_results_Model4.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

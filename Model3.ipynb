{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83849b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This program trains a binary classification model on image data (human face images with and without eyeglasses), \n",
    "saves the trained model, and classifies new/test images using the model. Also called binary image classification model.\n",
    "It utilizes the Keras library and follows the typical structure of a Convolutional Neural Network (CNN) model. \n",
    "The trained model predicts/classifies the test/new images as: 0 - No Eye glasses & 1 - Eye glasses present.\n",
    "\n",
    "This program is hosted online via Streamlit community cloud. \n",
    "Streamlit web app is created that allows users to upload an image, classify it using pre-trained models, and\n",
    "display the result.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import h5py\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up training and validation directories\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'test'\n",
    "\n",
    "# Counting the number of images in training and validation directories\n",
    "train_count = len(os.listdir('train/none')) + len(os.listdir('train/present'))\n",
    "test_count = len(os.listdir('test/none')) + len(os.listdir('test/present'))\n",
    "\n",
    "# Setting up image counts for training and validation\n",
    "nb_train_samples = train_count\n",
    "nb_validation_samples = test_count\n",
    "\n",
    "# Setting up training parameters\n",
    "epochs = 50    # specific for Model 2\n",
    "batch_size = 100\n",
    "\n",
    "# Setting image dimensions\n",
    "img_width, img_height = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the image data format\n",
    "if K.image_data_format() == 'channels_first':\n",
    "\tinput_shape = (3, img_width, img_height)\n",
    "else:\n",
    "\tinput_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5d005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Adding Convolutional and Pooling layers\n",
    "model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening and adding Dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af28c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "\t\t\toptimizer='rmsprop',\n",
    "\t\t\tmetrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "\trescale=1. / 255,\n",
    "\tshear_range=0.2,\n",
    "\tzoom_range=0.2,\n",
    "\thorizontal_flip=True)\n",
    "\n",
    "# Setting up data normalization for testing\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Creating data generators for training and validation\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,target_size=(img_width, img_height),\n",
    "batch_size=batch_size, class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "\tvalidation_data_dir,\n",
    "\ttarget_size=(img_width, img_height),\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='binary')\n",
    "\n",
    "# Training the model\n",
    "history=model.fit_generator(\n",
    "    train_generator,\n",
    "\tsteps_per_epoch=nb_train_samples // batch_size,\n",
    "\tepochs=epochs,\n",
    "\tvalidation_data=validation_generator,\n",
    "\tvalidation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e1024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting loss and accuracy over epochs\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "# Plotting loss & validation loss\n",
    "plt.subplot(1,2,1)\n",
    "sns.lineplot(x=history.epoch, y=history.history['loss'], color='red', label='Train Loss')\n",
    "sns.lineplot(x=history.epoch, y=history.history['val_loss'], color='orange', label='Val Loss')\n",
    "plt.title('Loss on train vs test')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Plotting accuracy and validation accuracy\n",
    "plt.subplot(1,2,2)\n",
    "sns.lineplot(x=history.epoch, y=history.history['accuracy'], color='blue', label='Train Accuracy')\n",
    "sns.lineplot(x=history.epoch, y=history.history['val_accuracy'], color='green', label='Val Accuracy')\n",
    "plt.title('Accuracy on train vs test')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained model\n",
    "model.save('Model3.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf707e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Setting up data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "\trescale=1. / 255,\n",
    "\tshear_range=0.2,\n",
    "\tzoom_range=0.2,\n",
    "\thorizontal_flip=True)\n",
    "\n",
    "# Setting up data normalization for testing\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Creating data generators for training and validation\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,target_size=(img_width, img_height),\n",
    "batch_size=batch_size, class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "\tvalidation_data_dir,\n",
    "\ttarget_size=(img_width, img_height),\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='binary')\n",
    "\n",
    "# Load the saved model\n",
    "from keras.models import load_model\n",
    "model = load_model('Model3.h5')\n",
    "\n",
    "# Generate predictions for the validation dataset\n",
    "validation_generator.reset()  # Reset generator to start from beginning\n",
    "y_pred = model.predict_generator(validation_generator, steps=len(validation_generator), verbose=1)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Get true labels\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_true, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the trained model for predictions\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('Model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2fbb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on test/new images using the trained model from the above.\n",
    "import glob\n",
    "\n",
    "# Setting the directory for testing images\n",
    "folder_dir = \"/Users/tabal/OneDrive/Desktop/Data Capstone/Pictures for Testing\"\n",
    "\n",
    "# Looping through each image in the directory\n",
    "for image in glob.iglob(f'{folder_dir}/*'):\n",
    "    \n",
    "    # Loading and preprocessing the image\n",
    "    load_image = load_img(image, target_size=(224, 224))\n",
    "    img = img_to_array(load_image)\n",
    "    img = preprocess_input(img.reshape(1,224,224,3))\n",
    "    \n",
    "    # Making predictions using the loaded model\n",
    "    label = model.predict(img)\n",
    "    \n",
    "    # Displaying the predicted class (0 - No Eye glasses , 1 - Eye glasses present) for each image in the folder\n",
    "    print(\"Predicted Class (0 - None , 1- Present) for \", os.path.basename(image), \" is:\", round(label[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851928a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on test/new images using the trained model from the above and exporting classification\n",
    "# results to an Excel file.\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Setting the directory for testing images\n",
    "# folder_dir = \"/Users/tabal/OneDrive/Desktop/Data Capstone/Pictures for Testing\"\n",
    "folder_dir = \"/Users/tabal/Downloads/new_faces\"\n",
    "\n",
    "# Create an empty list to store prediction results\n",
    "prediction_results = []\n",
    "\n",
    "# Looping through each image in the directory\n",
    "for image in glob.iglob(f'{folder_dir}/*'):\n",
    "    \n",
    "    # Loading and preprocessing the image\n",
    "    load_image = load_img(image, target_size=(224, 224))\n",
    "    img = img_to_array(load_image)\n",
    "    img = preprocess_input(img.reshape(1,224,224,3))\n",
    "    \n",
    "    # Making predictions using the loaded model\n",
    "    label = model.predict(img)\n",
    "    \n",
    "    # Append the prediction results to the list\n",
    "    prediction_results.append({\n",
    "        'Image Name': os.path.basename(image),\n",
    "        'Prediction': round(label[0][0])})\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df = pd.DataFrame(prediction_results)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('classification_results_Model3.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
